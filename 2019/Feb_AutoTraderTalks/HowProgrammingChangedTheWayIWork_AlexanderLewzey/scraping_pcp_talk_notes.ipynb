{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "this script does not work anymore, but gives you an idea of how to go about scraping a website\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-02-2019 09:11:36 DEBUG    [__init__.py:90] backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "# default modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Callable, Union\n",
    "%matplotlib inline\n",
    "import os\n",
    "import shelve\n",
    "import functools\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting pandas display settings\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logger\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s [%(filename)s:%(lineno)d] %(message)s',\n",
    "    datefmt = '%d-%m-%Y %H:%M:%S',\n",
    "    level=logging.DEBUG,\n",
    "    # filename='logs.txt'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "\n",
    "class ShelveApi:\n",
    "    \"\"\"\n",
    "    simple wrapper for loading and saving shelves\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def load_from_shelve(self, key):\n",
    "        \"\"\"\n",
    "        load the value that corresponds to a certain key from a shelve\n",
    "        \"\"\"\n",
    "        d = shelve.open(self.filename, 'c')\n",
    "        val = d[key]\n",
    "        d.close()\n",
    "        return val\n",
    "    \n",
    "    def save_to_shelve(self, val, key):\n",
    "        \"\"\"\n",
    "        save values to shelve that corresponds to a specified key\n",
    "        \"\"\"\n",
    "        d = shelve.open(self.filename, 'c')\n",
    "        d[key] = val\n",
    "        d.close()\n",
    "    \n",
    "    def show_keys(self):\n",
    "        \"\"\"\n",
    "        show all keys that exisit in the shelve\n",
    "        \"\"\"\n",
    "        d = shelve.open(self.filename, 'c')\n",
    "        print(list(d.keys()))\n",
    "        d.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scraping pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webscraping/parsing modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions\n",
    "BASE_URL = 'https://www.some_url.co.uk' # not a real url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating shelve wrapper class\n",
    "pcp_shelve = ShelveApi('pcp_shelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using selenium to activate javascript and get html\n",
    "\n",
    "driver = webdriver.Chrome() # opens a browser which python can automate, NB you need to download ChromeDriver.exe and have it in the same\n",
    "# folder as the script for this to work\n",
    "driver.get('https://www.some_url.co.uk/data_page') # load page\n",
    "\n",
    "driver.find_element_by_css_selector(\"a[href*='java'][href*='All']\").click() # using CSS selectors to click on the element of the page \n",
    "# where the href of the page element contains the text 'java' and 'All'\n",
    "pcp_shelve.save_to_shelve(driver.page_source,'index_page_html') # grabbing the subsequent page content and saving it\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.peakcottageplants.co.uk/ViewPlantDetails.aspx?PlantID=4',\n",
       " 'http://www.peakcottageplants.co.uk/ViewPlantDetails.aspx?PlantID=8',\n",
       " 'http://www.peakcottageplants.co.uk/ViewPlantDetails.aspx?PlantID=9',\n",
       " 'http://www.peakcottageplants.co.uk/ViewPlantDetails.aspx?PlantID=11',\n",
       " 'http://www.peakcottageplants.co.uk/ViewPlantDetails.aspx?PlantID=15']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retiving each plant page url from html\n",
    "\n",
    "# this block of code uses beautiful soup to grab all the hrefs of the page we just saved\n",
    "# it then uses a list comprehesion to filter be hrefs that contain the string 'PlantID'\n",
    "\n",
    "def get_all_urls(soup) -> List:\n",
    "    \"\"\"\n",
    "    return a list of all the hrefs included in an soup object\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.has_attr('href'):\n",
    "            urls.append(link.get('href'))\n",
    "    return urls\n",
    "\n",
    "soup = BeautifulSoup(pages['plant_index'], 'html.parser')\n",
    "plant_id_urls = [urljoin(BASE_URL, url_tail) for url_tail in get_all_urls(soup) if 'PlantID' in url_tail]\n",
    "plant_id_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requesting html for each plant page in the list\n",
    "\n",
    "def get_rsps(urls: List) -> List[requests.models.Response]:\n",
    "    \"\"\"\n",
    "    return a list of request responses\n",
    "    \"\"\"\n",
    "    return [requests.get(url) for url in urls]\n",
    "\n",
    "plant_page_rsps = get_rsps(plant_id_urls)\n",
    "pcp_shelve.save_to_shelve(plant_page_rsps, 'plant_page_rsps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plant page parser tools\n",
    "\n",
    "def trim(string):\n",
    "    \"\"\"\n",
    "    remove all escape characters and double white spaces from a string\n",
    "    \"\"\"\n",
    "    return ' '.join(string.split())\n",
    "\n",
    "# this class takes in an indivicual plant pages and uses beautful soup to grab\n",
    "# the elements of the page we are interested it, this will always to specific to\n",
    "# the page you are scraping\n",
    "\n",
    "class PlantPageParser:\n",
    "    \"\"\"\n",
    "    parse key information from plant page html into a dictionary\n",
    "    \"\"\"\n",
    "    def __init__(self, html):\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    @property\n",
    "    def get_table(self):\n",
    "        return self.soup.find('table', {'style': 'width:390px'})\n",
    "    \n",
    "    @property\n",
    "    def parse_table_rows(self) -> Dict:\n",
    "        data = {}\n",
    "        for tr in self.get_table.find_all('tr'):\n",
    "            field, val = tr.find_all('td')\n",
    "            data[trim(field.text)] = trim(val.text)\n",
    "        return data\n",
    "    \n",
    "    @property\n",
    "    def get_plant_nm(self) -> Dict:\n",
    "        nm = self.soup.find('h2').text\n",
    "        return {'Name:': trim(nm)}\n",
    "    \n",
    "    @property\n",
    "    def get_parsed_page(self) -> Dict:\n",
    "        return {**self.get_plant_nm, **self.parse_table_rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Name:</th>\n",
       "      <th>Conditions:</th>\n",
       "      <th>Description:</th>\n",
       "      <th>Flower Colour:</th>\n",
       "      <th>Hardiness:</th>\n",
       "      <th>Height (cm):</th>\n",
       "      <th>In Stock?:</th>\n",
       "      <th>Leaf Colour:</th>\n",
       "      <th>Name:</th>\n",
       "      <th>Season of Interest:</th>\n",
       "      <th>Soil Type:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yarrow</td>\n",
       "      <td>Full Sun</td>\n",
       "      <td>A vigorous plant with bright magenta-pink flow...</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fully Hardy</td>\n",
       "      <td>60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Green</td>\n",
       "      <td>Achillea millefolium - Cerise Queen</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moist but well-drained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sneezewort</td>\n",
       "      <td>Full Sun</td>\n",
       "      <td>This strong perennial bears tight, button-like...</td>\n",
       "      <td>White</td>\n",
       "      <td>Fully Hardy</td>\n",
       "      <td>60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Green</td>\n",
       "      <td>Achillea ptarmica - Benary's Pearl</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moist but well-drained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not defined</td>\n",
       "      <td>Sun or part shade</td>\n",
       "      <td>Soft pink flowers in a large umbel throughout ...</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fully Hardy</td>\n",
       "      <td>60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Green</td>\n",
       "      <td>Achillea siberica - Love Parade</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moist but well-drained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monkshood</td>\n",
       "      <td>Partial shade</td>\n",
       "      <td>White flowers that become tinged with rose as ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Fully Hardy</td>\n",
       "      <td>90</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Dark green</td>\n",
       "      <td>Aconitum bicolor - Mother of Pearl</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moist but well-drained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wolf's Bane</td>\n",
       "      <td>Partial shade</td>\n",
       "      <td>Panicles of pale yellow, hooded flowers are pr...</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Fully Hardy</td>\n",
       "      <td>100</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Light green</td>\n",
       "      <td>Aconitum lycoctonum syn. Vulparia</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Any</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Common Name:        Conditions:  \\\n",
       "0       Yarrow           Full Sun   \n",
       "1   Sneezewort           Full Sun   \n",
       "2  Not defined  Sun or part shade   \n",
       "3    Monkshood      Partial shade   \n",
       "4  Wolf's Bane      Partial shade   \n",
       "\n",
       "                                        Description: Flower Colour:  \\\n",
       "0  A vigorous plant with bright magenta-pink flow...           Pink   \n",
       "1  This strong perennial bears tight, button-like...          White   \n",
       "2  Soft pink flowers in a large umbel throughout ...           Pink   \n",
       "3  White flowers that become tinged with rose as ...          White   \n",
       "4  Panicles of pale yellow, hooded flowers are pr...         Yellow   \n",
       "\n",
       "    Hardiness: Height (cm): In Stock?: Leaf Colour:  \\\n",
       "0  Fully Hardy           60        Yes        Green   \n",
       "1  Fully Hardy           60        Yes        Green   \n",
       "2  Fully Hardy           60        Yes        Green   \n",
       "3  Fully Hardy           90        Yes   Dark green   \n",
       "4  Fully Hardy          100        Yes  Light green   \n",
       "\n",
       "                                 Name: Season of Interest:  \\\n",
       "0  Achillea millefolium - Cerise Queen              Summer   \n",
       "1   Achillea ptarmica - Benary's Pearl              Summer   \n",
       "2      Achillea siberica - Love Parade              Summer   \n",
       "3   Aconitum bicolor - Mother of Pearl              Summer   \n",
       "4    Aconitum lycoctonum syn. Vulparia              Summer   \n",
       "\n",
       "               Soil Type:  \n",
       "0  Moist but well-drained  \n",
       "1  Moist but well-drained  \n",
       "2  Moist but well-drained  \n",
       "3  Moist but well-drained  \n",
       "4                     Any  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsing pages into a dataframe\n",
    "\n",
    "data = []\n",
    "for rsp in rsps:\n",
    "    parse = PlantPageParser(rsp.text)\n",
    "    data.append(parse.get_parsed_page)\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pcp_plants.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
